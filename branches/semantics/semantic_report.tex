\documentclass[]{article}

\usepackage{xltxtra}
\usepackage{rotating}
\usepackage{graphicx}
\usepackage[xetex, breaklinks=true, hyperfootnotes=false, hyperfigures=false, colorlinks=true]{hyperref}
\usepackage{fontspec}

\title{Preliminary notes on tests of a synonym-detector}
\author{Chris Forstall}

\date{2012-06-03}

\begin{document}
	
	\setmainfont{Arial}
	
	\maketitle


	\section{Introduction}
		
		We have successfully implemented the dictionary-based approach to synonym detection of Jeff Rydberg-Cox.  This method assigns a similarity score to two Latin headwords based on the number of shared terms in their English definitions.  An arbitrary similarity threshold is selected, above which words are considered to match.  A stoplist of very common English words are deleted from the dictionary entries before calculating similarity.
		
		By varying the threshold as well as the size of the stoplist, we can alter the number and the selection of synonyms over the corpus.  Preliminary results suggest that a larger stoplist and a lower similarity threshold might provide the best distribution of synonyms in the dictionary, but results from Tesserae itself are confusing.  Some qualitative inspection of the synonym lists will be necessary to confirm that computer-assigned “matches” have some literary validity.

	\section{Method}
	
		
		We use a method developed by Jeff Rydberg-Cox for the Perseus “similar words” lookup tool, which is no longer available in Perseus 4.0.  The similarity of two words is a normalized count of the shared English terms in their respective entries in a Latin-English dictionary.  Rydberg-cox used the Perseus XML transcription of Lewis and Short; we have access to the same edition, but are still developing a method for extracting the English definitions from entries.  For now, our tests are done using the dictionary for Whitaker's Words (available at \url{http://archives.nd.edu/whitaker/dictpage.htm}).
		
	\subsection{Similarity}
		
		Each English entry is treated as a bag of words.  Where two different Latin headwords have the same orthography, their entries are concatenated.  Words on the stoplist, described below, are deleted.

		To calculate a normalized score for any two words, the total number of terms shared between the two entries is divided by the total number of words in the two entries.  For words occurring in both entries or several times in one entry, every instance is counted.
		
		For example, consider the two entries below:
		
		\vspace{1em}
		
		\begin{description}
			\item[alludo] frolic/play/sport around/with, play against; jest, make mocking allusion to; 
			\item[iocus] joke, jest, sport;
		\end{description}
		
		Assume for the moment that \emph{make} as well as the prepositions \emph{to}, \emph{with}, \emph{against}, and \emph{around} are stopwords.  The counts for these two entries look like this:
		
		\begin{tabular}{llll}
						&	alludo	&	jocus	\\
			allusion	&	1			&	0		\\
			frolic	&	1			&	0		\\
			jest		&	1			&	1		\\
			joke		&	0			&	1		\\
			mocking	&	1			&	0		\\
			play		&	2			&	0		\\
			sport		&	1			&	1		\\
			\hline
			total		&	7			&	3		\\
		\end{tabular}
		
		\vspace{1em}
		
		Their similarity would be calculated as follows:
		
		\vspace{1em}
		
		\begin{tabular}{lr}

			shared		&	4		\\
			total			&	10		\\
			\hline
			similarity	&	0.4	\\
		\end{tabular}
		
	\subsection{Stop words}
	
		The list of English terms to be excluded is determined by the number of entries in which a given term appears.  A word which appears in the definitions of very many different terms is unlikely to be as helpful in distinguishing meaning as a relatively rare word.  We therefore set an arbitrary cutoff, \emph{max heads}, the maximum number of Latin headwords under which an English term is found.  Larger values of \emph{max heads} mean we include more English words in our calculations; smaller values of \emph{max heads} mean more English words are ignored.
		
	\subsection{Synonymy}
	
		For the purposes of Tesserae's search algorithm, synonymy must be a binary decision.  Either two words are similar enough to match, or they aren't.  We set an arbitrary cutoff, \emph{min similarity}, at or above which words are considered to match.
		
	
	\subsection{Testing}
	
	In these tests we varied \emph{max heads} over the values 50, 100, and 200.  The dictionary has about 35,000 headwords in it, so even the largest of these values is relatively exclusive.  Independently, we varied \emph{min similarity} over the values 0.50, 0.70, and 0.90.
	
	The effects of these two variables were measured using automatic means.  The overall level of synonymy in the dictionary was measured by the distribution of synonyms.  The holistic effect upon Tesserae was gauged by the increase in the number of results returned by the standard Lucan 1 ~ Aeneid search.
		
	\section{Results and Discussion}
	
	\subsection{Dictionary-wide synonymy}
	
 	The figures below show, for various values of \emph{max heads} and \emph{min similarity}, how many words in the dictionary have a given number of synonyms.  Since words will still match themselves as well as their synonyms in a Tesserae search, the word itself is also counted in these graphs.  Thus, a word with no synonyms counts as 1, a word with a single synonym counts as 2, and so on.  The figures are shown on a log-log scale—the dropoff from left to right in all series is exponential.  Figures \ref{h50}–\ref{h200} compare the effect of different \emph{min similarity} values for a given \emph{max heads}.  Figures \ref{s50}–\ref{s90} compare the effect of different \emph{max heads} values for a given \emph{min similarity}.
	
	The effect of varying the similarity threshold was similar for all three stop lists (Figs. \ref{h50}–\ref{h200}).  The highest similiarity threshold produced the greatest number of Latin words with no synonyms besides themselves (the leftmost point on each graph).  Between 2 and 3 on the x-axis, that is, words matching one or two others besides themselves, the lines cross. After this, the most exclusive threshold drops off most steeply, while the most inclusive drops off much less so.  The shape of the drop-off does not seem linearly proportional to the similarity threshold: we gain more synonyms by going from 0.7 to 0.5 than from 0.9 to 0.7.  Likewise, the maximum number of synonyms an word in the dictionary has increases as we lower the similarity threshold, but it increases more from 0.7 to 0.5 than from 0.9 to 0.7.
	
	A slightly different pattern holds when we vary the size of the stop list for a given similarity threshold (Figs. \ref{s50}–\ref{s90}).  The three series perform very similarly at the left-hand side of the graph.  In the middle of the graph, series \emph{max heads}=50, the most exclusive value of this variable, produces more words for a given number of synonyms.  Then, at the right-hand side of the graph, this reverses and the more inclusive settings produce more words for a given number of synonyms, as well as a higher maximum number of synonyms.  This effect is lost as \emph{min similarity} becomes more exclusive (Fig. \ref{s90}).
	
	Since all three series have similar numbers of words with no synonyms besides themselves, the total number of words having any synonyms at all must be about the same for all three series.  It is reasonable that a smaller English stoplist will allow words to match more broadly, and increase the maximum number of synonyms any word in the dictionary can have.  Assuming that the total number of words having synonyms remains constant, we can see that as some words have more synonyms, the number of words having fewer synonyms must decrease.  The big question, here, is \emph{why} changing the English stoplist doesn't seem to affect the number of words matching only themselves.  Why as we allow words to match on more and more of the terms in their dictionary definitions, do the same words just match more of one another, without adding any of the singletons into the pool?
	
	These data suggest that a more even distribution of synonyms might be obtained with a relatively large stoplist and a relatively low threshold of similarity, i.e. low \emph{max heads} and low \emph{min similarity}.  This seems to produce fewer words with no synonyms, and to favour moderate rather than extreme numbers of synonyms for those words that have them.
	
	\subsection{Tesserae results}
	
	Table \ref{tesresults} shows the number of results returned by a Tesserae search on Lucan \emph{Bellum Civile} Book 1 and all of the \emph{Aeneid}, comparing results of a stem-based search with synonym searches at each of the nine combinations of \emph{max heads} and \emph{min similarity}.
	
	These results are very difficult to explain.  On the one hand, increasing the similarity threshold decreases the number of results, as one would expect.  On the other hand, the most severe stoplist (\emph{max heads}=50) produces the most results.  While in theory this is possible, if the majority of the words shared by the two poems are from the middle portion of the range shown in Figs. \ref{s50}–\ref{s90}, it is very surprising.
	
	More research is needed to determine what has caused this phenomenon, or whether it is an error.  The next step will be to test levels of synonymy in the poetic corpus in the same way that we have done here for the dictionary.  In particular, we must examine what words are matching between then two poems, and how many synonyms these words tend to have.
	
	\begin{table}
	\caption{Number of Tesserae results returned under various synonymy settings.  All searches also applied the default Latin stoplist.\label{tesresults}}
	
	\vspace{1em}

	\begin{tabular}{r|rrr}
		max heads	&	\multicolumn{3}{c}{min similarity} 	\\
						&	0.5		&	0.7		&	0.9 			\\		\hline
				 50	&	39,848	&	16,781	&	16,138		\\
				100	&	31,056	&	 8,560	&	 8,290		\\
				200	&	30,230	&	 8,229	&	 8,151		\\
	\end{tabular}

	\vspace{1em}

	\begin{tabular}{ll}
			stem search alone:	&	6,665
	\end{tabular}

	\end{table}
	
	\subsection{Subjective evaluation}
	
	These experiments also provide us with several products that should be evaluated subjectively by humans at some point.  First, for each of the nine combinations of \emph{max heads} and \emph{min similarity} values, a “thesaurus” is produced, giving for each word in the dictionary all those considered synonyms as well as their individual similarity scores.  It would be helpful to look at this list and give some sort of subjective assessment of whether the majority of the synonyms were relevent from a literary perspective.
	
	Second, the Tesserae results should be examined by hand, to see what proportion of the synonym matches are significant.  We should be able automatically to correlate matches returned by this search with those previously hand-graded, but any new results could only be evaluated by humans.
	
	\clearpage
	
	\section{Figures}
	
	\begin{figure}[h]
		\includegraphics[width=\textwidth]{batch/h50.png}
		\caption{Varying \emph{min similiarity} at \emph{max heads} = 50.  English terms occurring in more than 50 different dictionary entries were excluded.  The three series show three different similarity thresholds, above which Latin headwords were considered synonyms.\label{h50}}
	\end{figure}

	\begin{figure}
		\includegraphics[width=\textwidth]{batch/h100.png}
		\caption{Varying \emph{min similiarity} at \emph{max heads} = 100.  English terms occurring in more than 100 different dictionary entries were excluded.  The three series show three different similarity thresholds, above which Latin headwords were considered synonyms.\label{h100}}
	\end{figure}

	\begin{figure}
		\includegraphics[width=\textwidth]{batch/h200.png}
		\caption{Varying \emph{min similiarity} at \emph{max heads} = 200.  English terms occurring in more than 200 different dictionary entries were excluded.  The three series show three different similarity thresholds, above which Latin headwords were considered synonyms.\label{h200}}
	\end{figure}

	\begin{figure}
		\includegraphics[width=\textwidth]{batch/s50.png}
		\caption{Varying \emph{max heads} at \emph{min similarity} = 0.5.  Latin words having a similarity index of 0.5 or higher were considered synonyms.  The three series show three different stoplist cutoffs: English terms occurring in more than \emph{max heads} different dictionary entries were excluded.\label{s50}}
	\end{figure}

	\begin{figure}
		\includegraphics[width=\textwidth]{batch/s70.png}
		\caption{Varying \emph{max heads} at \emph{min similarity} = 0.7.  Latin words having a similarity index of 0.7 or higher were considered synonyms.  The three series show three different stoplist cutoffs: English terms occurring in more than \emph{max heads} different dictionary entries were excluded.\label{s70}}
	\end{figure}

	\begin{figure}
		\includegraphics[width=\textwidth]{batch/s90.png}
		\caption{Varying \emph{max heads} at \emph{min similarity} = 0.9.  Latin words having a similarity index of 0.9 or higher were considered synonyms.  The three series show three different stoplist cutoffs: English terms occurring in more than \emph{max heads} different dictionary entries were excluded.\label{s90}}
	\end{figure}
	
\end{document}